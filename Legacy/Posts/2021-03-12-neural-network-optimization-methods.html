<!DOCTYPE html>
<html lang="en">
  




<head>
	<meta charset="utf-8">
	<title>Neural Network Optimization Methods and Algorithms - Tropical Insights</title>
	<link rel="canonical" href="http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html">
	<meta name="description" content="Some neural network optimization algorithms mostly to implement momentum when doing back propagation.">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:4000"},
  "headline": "Neural Network Optimization Methods and Algorithms",
  "abstract": "Some neural network optimization algorithms mostly to implement momentum when doing back propagation.",
    "keywords": "coding, machine learning, optimization, deep Neural networks",
    "wordcount": "1711",
    "image": ["http://localhost:4000/assets/imgposts/20210312/nnet_optimization.jpg"],
  "datePublished": "2021-03-12 13:32:20 -0600",
  "dateModified": "2021-03-12 13:32:20 -0600",
  "author": {
    "@type": "Person",
    "name": "Armando Maynez"},
  "publisher": {
    "@type":  "Organization",
    "logo": {
        "@type": "ImageObject",
        "encodingFormat": "image/png",
        "contentUrl": "http://localhost:4000/assets/img/branding/logo.png",
        "url": "http://localhost:4000/assets/img/branding/logo.png"},
    "name" : "Tropical Insights"}
}
</script>
<!-- Open Graph data -->
<meta property="og:url" content="http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html"/>
<meta property="og:type" content="article"/>
<meta property="og:title" content="Neural Network Optimization Methods and Algorithms"/>
<meta property="og:description" content="Some neural network optimization algorithms mostly to implement momentum when doing back propagation."/>
<meta property="og:image" content="http://localhost:4000/assets/imgposts/20210312/nnet_optimization.jpg"/>
<meta property="og:image:alt" content="Neural Network Optimization Methods and Algorithms"/>
<meta property="og:site_name" content="Tropical Insights" />
<meta property="article:published_time" content="2021-03-12 13:32:20 -0600" />
<meta property="article:modified_time" content="2021-03-12 13:32:20 -0600" />
<meta property="article:tag" content="coding, machine learning, optimization, deep Neural networks" />
<meta property="fb:admins" content="" />
<!-- Schema.org markup for Google -->
<meta itemprop="name" content="Neural Network Optimization Methods and Algorithms">
<meta itemprop="description" content="Some neural network optimization algorithms mostly to implement momentum when doing back propagation.">
<meta itemprop="image" content="http://localhost:4000/assets/imgposts/20210312/nnet_optimization.jpg">
<!-- Twitter Card data -->
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="">
<meta name="twitter:title" content="Neural Network Optimization Methods and Algorithms">
<meta name="twitter:description" content="Some neural network optimization algorithms mostly to implement momentum when doing back propagation.">
<meta name="twitter:creator" content="">
<meta data-rh="true" name="twitter:label1" content="Word count"/>
<meta data-rh="true" name="twitter:data1" content="1711"/>
<meta name="twitter:image:src" content="http://localhost:4000/assets/img/posts/20210312/nnet_optimization.jpg">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#311e3e">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#311e3e">
	<!-- Google Fonts -->
	<link rel="preconnect" href="https://fonts.gstatic.com" />
	<style>
/* latin */
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 400;
  src: url(https://fonts.gstatic.com/s/lora/v17/0QIvMX1D_JOuMwr7I_FMl_E.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Lora';
  font-style: normal;
  font-weight: 600;
  src: url(https://fonts.gstatic.com/s/lora/v17/0QIvMX1D_JOuMwr7I_FMl_E.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 200;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xKydSBYKcSV-LCoeQqfX1RYOo3i94_wlxdu3cOWxw.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 400;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xK3dSBYKcSV-LCoeQqfX1RYOo3qOK7lujVj9w.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin */
@font-face {
  font-family: 'Source Sans Pro';
  font-style: normal;
  font-weight: 700;
  src: url(https://fonts.gstatic.com/s/sourcesanspro/v14/6xKydSBYKcSV-LCoeQqfX1RYOo3ig4vwlxdu3cOWxw.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
	</style>
	<!-- <link href="https://fonts.googleapis.com/css?family=Lora:400,600|Source+Sans+Pro:200,400,700" rel="stylesheet"> -->
	<!-- Font Awesome -->
	<link rel="stylesheet" href="../../assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="../../assets/css/main.css">
	




<link rel="icon" href="../../assets/img/favicon/favicon.ico" type="image/x-icon">
<link rel="apple-touch-icon" href="../../assets/img/favicon/favicon.ico">
<link rel="apple-touch-icon" sizes="72x72" href="../../assets/img/favicon/favicon.ico">
<link rel="apple-touch-icon" sizes="114x114" href="../../assets/img/favicon/favicon.ico">
	
	<link rel="stylesheet" href="../../assets/css/highlighter/syntax-base16.monokai.dark.css">
	
</head>

  <body>
    




<section class="hidden">
  <div class="post">
      <a  class="post-list-title" href="../../Legacy/Posts/2021-03-12-neural-network-optimization-methods.html">Neural Network Optimization Methods and Algorithms</a>
      

  <span class = "post-card-meta">
  
  
    <span class="meta-pre"></span>
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-03-12T14:32:20-05:00">March 12, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        8 minute read
      
    </span>
  
  
  </span>

        <div class="post-excerpt">
            <p>For the seemingly small project I undertook of <a href="./deep-q-learning-tic-tac-toe.html">creating a machine learning neural network that could learn by itself to play tic-tac-toe</a>, I bumped into the necesity of implementing at least one momentum algorithm for the optimization of the network during backpropagation.</p><p>And since my original post for the TicTacToe project is quite large already, I decided to post separately these optimization methods and how did I implement them in my code.</p><h3 id="adam">Adam</h3><p><a href="https://ruder.io/optimizing-gradient-descent/index.html#adam">source</a></p><p>Adaptive Moment Estimation (Adam) is an optimization method that computes adaptive learning rates for each weight and bias. In addition to storing an exponentially decaying average of...<a class="read-more" href="../../Legacy/Posts/2021-03-12-neural-network-optimization-methods.html"> read more</a>
        </div>
  </div>
</section>
<div class="flex-container transparent">
  




<header class="main-header">
  <div class="wrapper">
    <div class="header-flex">
      <div class="menu-icon-container">
        <span class="menu-icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
      </div>
      <nav class="main-nav">
        <span class="menu-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
        <ul>
          <li>
            <div class="theme-toggle night">
    <input class="night" type="checkbox" id="theme-switch">
    <label class="night" for="theme-switch">
        <div class="toggle night"></div>
        <div class="names night">             
        <p class="light night"><svg class="night" width="20" viewBox="0 0 25 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
            <path class="night" d="M12.5 2.49871C11.3401 2.50016 10.2282 2.96156 9.40801 3.78171C8.58785 4.60187 8.12645 5.71383 8.125 6.87371C8.125 7.03947 8.19085 7.19844 8.30806 7.31565C8.42527 7.43286 8.58424 7.49871 8.75 7.49871C8.91576 7.49871 9.07473 7.43286 9.19194 7.31565C9.30915 7.19844 9.375 7.03947 9.375 6.87371C9.37593 6.04519 9.70547 5.25088 10.2913 4.66503C10.8772 4.07918 11.6715 3.74964 12.5 3.74871C12.6658 3.74871 12.8247 3.68286 12.9419 3.56565C13.0592 3.44844 13.125 3.28947 13.125 3.12371C13.125 2.95795 13.0592 2.79898 12.9419 2.68177C12.8247 2.56456 12.6658 2.49871 12.5 2.49871V2.49871ZM12.5 -0.00129131C8.47891 -0.00129131 5.62031 3.26238 5.625 6.88269C5.62487 8.54403 6.22974 10.1486 7.32656 11.3964C8.32891 12.5378 9.29062 14.4007 9.375 14.9987L9.37734 17.9358C9.37744 18.0587 9.41402 18.1787 9.48242 18.2807L10.4395 19.7198C10.4964 19.8055 10.5737 19.8758 10.6644 19.9245C10.7551 19.9731 10.8564 19.9986 10.9594 19.9987H14.0395C14.1426 19.9988 14.2441 19.9734 14.3351 19.9247C14.426 19.8761 14.5034 19.8057 14.5605 19.7198L15.5176 18.28C15.5854 18.1776 15.6219 18.0578 15.6227 17.935L15.625 14.9987C15.7129 14.3846 16.6797 12.5303 17.6734 11.3964C18.5434 10.4028 19.1087 9.17963 19.3015 7.87318C19.4944 6.56673 19.3066 5.23238 18.7608 4.02985C18.215 2.82732 17.3342 1.80757 16.2238 1.09264C15.1135 0.377721 13.8206 -0.00207746 12.5 -0.00129131V-0.00129131ZM14.3727 17.7452L13.7047 18.7487H11.2937L10.6273 17.7452V17.4987H14.3738L14.3727 17.7452ZM14.375 16.2487H10.625L10.6227 14.9987H14.375V16.2487ZM16.7348 10.5725C16.1879 11.1956 15.316 12.4511 14.7594 13.7479H10.243C9.68516 12.4507 8.81328 11.1956 8.26641 10.5725C7.36971 9.5491 6.87599 8.2344 6.87734 6.87371C6.87031 3.8659 9.23594 1.24871 12.5 1.24871C15.602 1.24871 18.125 3.77176 18.125 6.87371C18.1249 8.23456 17.6305 9.54904 16.7336 10.5725H16.7348ZM3.75 6.87371C3.75 6.70795 3.68415 6.54898 3.56694 6.43177C3.44973 6.31456 3.29076 6.24871 3.125 6.24871H0.625C0.45924 6.24871 0.300269 6.31456 0.183058 6.43177C0.065848 6.54898 0 6.70795 0 6.87371C0 7.03947 0.065848 7.19844 0.183058 7.31565C0.300269 7.43286 0.45924 7.49871 0.625 7.49871H3.125C3.29076 7.49871 3.44973 7.43286 3.56694 7.31565C3.68415 7.19844 3.75 7.03947 3.75 6.87371ZM20.625 2.49871C20.7221 2.49849 20.8178 2.4759 20.9047 2.43269L23.4047 1.18269C23.5529 1.10852 23.6657 0.978483 23.718 0.821201C23.7704 0.66392 23.7582 0.492273 23.684 0.344021C23.6473 0.270614 23.5964 0.205161 23.5344 0.151397C23.4724 0.0976336 23.4004 0.0566132 23.3225 0.0306781C23.1652 -0.0217002 22.9936 -0.00945342 22.8453 0.0647243L20.3453 1.31472C20.2194 1.37771 20.1184 1.48136 20.0588 1.60889C19.9991 1.73643 19.9843 1.88037 20.0166 2.0174C20.049 2.15442 20.1267 2.2765 20.2371 2.36386C20.3475 2.45122 20.4842 2.49873 20.625 2.49871ZM24.375 6.24871H21.875C21.7092 6.24871 21.5503 6.31456 21.4331 6.43177C21.3158 6.54898 21.25 6.70795 21.25 6.87371C21.25 7.03947 21.3158 7.19844 21.4331 7.31565C21.5503 7.43286 21.7092 7.49871 21.875 7.49871H24.375C24.5408 7.49871 24.6997 7.43286 24.8169 7.31565C24.9342 7.19844 25 7.03947 25 6.87371C25 6.70795 24.9342 6.54898 24.8169 6.43177C24.6997 6.31456 24.5408 6.24871 24.375 6.24871ZM4.65469 1.31472L2.15469 0.0647243C2.08128 0.0279952 2.00136 0.00608435 1.91948 0.00024269C1.83761 -0.00559897 1.75539 0.004743 1.67751 0.0306781C1.52023 0.0830564 1.39019 0.195769 1.31602 0.344021C1.24184 0.492273 1.22959 0.66392 1.28197 0.821201C1.33435 0.978483 1.44706 1.10852 1.59531 1.18269L4.09531 2.43269C4.18223 2.4759 4.27794 2.49849 4.375 2.49871C4.5158 2.49873 4.65248 2.45122 4.7629 2.36386C4.87332 2.2765 4.951 2.15442 4.98337 2.0174C5.01574 1.88037 5.0009 1.73643 4.94124 1.60889C4.88158 1.48136 4.78061 1.37771 4.65469 1.31472ZM23.4047 12.5647L20.9047 11.3147C20.7564 11.2405 20.5847 11.2283 20.4274 11.2807C20.2701 11.3332 20.14 11.4459 20.0658 11.5942C19.9916 11.7425 19.9794 11.9142 20.0318 12.0715C20.0842 12.2289 20.197 12.3589 20.3453 12.4331L22.8453 13.6831C22.9936 13.7573 23.1653 13.7695 23.3226 13.7171C23.4799 13.6647 23.61 13.5519 23.6842 13.4036C23.7584 13.2553 23.7706 13.0836 23.7182 12.9263C23.6658 12.769 23.553 12.6389 23.4047 12.5647V12.5647ZM4.375 11.2487C4.27794 11.2489 4.18223 11.2715 4.09531 11.3147L1.59531 12.5647C1.44701 12.6389 1.33425 12.769 1.28183 12.9263C1.25588 13.0042 1.24552 13.0864 1.25135 13.1683C1.25719 13.2502 1.27909 13.3302 1.31582 13.4036C1.35255 13.477 1.40338 13.5425 1.46542 13.5963C1.52745 13.6501 1.59947 13.6911 1.67737 13.7171C1.83469 13.7695 2.00638 13.7573 2.15469 13.6831L4.65469 12.4331C4.78083 12.3702 4.88202 12.2666 4.94183 12.1389C5.00164 12.0113 5.01656 11.8672 4.98417 11.7301C4.95178 11.5929 4.87397 11.4707 4.76339 11.3833C4.65281 11.2959 4.51594 11.2485 4.375 11.2487V11.2487Z" /></svg></p>
        <p class="dark night"><svg class="night" width="20" viewBox="0 0 25 21" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
            <path class="night" d="M6.39614 3.72646C7.50591 1.56178 9.72622 0.00900831 12.4782 0.00114817C13.8006 -0.00388798 15.0965 0.375153 16.2101 1.09278C17.3237 1.8104 18.2079 2.83612 18.7564 4.04682C19.3049 5.25751 19.4945 6.60175 19.3024 7.91818C19.1103 9.23461 18.5447 10.4673 17.6735 11.4683C17.5227 11.6416 17.3516 11.859 17.1739 12.1069L9.47856 6.12184C9.65443 5.45016 10.046 4.85578 10.5924 4.43118C11.1387 4.00657 11.8093 3.77554 12.4997 3.77401C12.6654 3.77401 12.8244 3.70776 12.9416 3.58984C13.0588 3.47191 13.1247 3.31197 13.1247 3.1452C13.1247 2.97843 13.0588 2.81849 12.9416 2.70057C12.8244 2.58264 12.6654 2.51639 12.4997 2.51639C11.6212 2.5173 10.7634 2.78383 10.0374 3.28141C9.31146 3.77899 8.75092 4.48463 8.42856 5.30674L6.39614 3.72646ZM6.39614 10.0841C6.64968 10.5817 6.96225 11.0465 7.327 11.4683C7.97231 12.2091 8.98169 13.7568 9.36645 15.0624C9.36645 15.0726 9.36919 15.0828 9.37075 15.093H12.8372L6.39614 10.0841ZM9.37466 16.3502V17.8574C9.37584 18.1045 9.44934 18.3458 9.58599 18.5511L10.2536 19.5607C10.3675 19.7335 10.5221 19.8753 10.7037 19.9734C10.8852 20.0715 11.0881 20.1229 11.2942 20.1231H13.7047C13.9107 20.1231 14.1135 20.0718 14.2951 19.9739C14.4766 19.876 14.6313 19.7345 14.7454 19.5619L15.4129 18.5511C15.5492 18.3451 15.622 18.1033 15.6223 17.8558V17.2581L14.4528 16.3502H9.37466Z"/>
            <path class="night" d="M0.131556 1.2363L0.898352 0.243172C0.948738 0.177883 1.01142 0.123229 1.08282 0.0823368C1.15423 0.0414448 1.23294 0.0151171 1.31446 0.00486006C1.39598 -0.00539702 1.47872 0.000617709 1.55793 0.0225602C1.63714 0.0445026 1.71127 0.0819422 1.77609 0.132737L24.7585 18.0039C24.8894 18.1062 24.9745 18.2567 24.9952 18.4221C25.0158 18.5876 24.9703 18.7545 24.8687 18.8862L24.1015 19.8794C24.0511 19.9446 23.9884 19.9992 23.917 20.0401C23.8457 20.0809 23.767 20.1072 23.6855 20.1175C23.6041 20.1277 23.5214 20.1217 23.4422 20.0998C23.363 20.0779 23.2889 20.0405 23.2241 19.9898L0.241322 2.1186C0.110489 2.01624 0.0254259 1.86578 0.00484145 1.70032C-0.015743 1.53486 0.0298368 1.36795 0.131556 1.2363V1.2363Z"/>
            </svg></p>
        </div>
    </label>
</div>
          </li>
          <li>
            <a href="../../">
              <div class="left">
                Home
              </div>  
              <div class="right">
                <svg width="24px" aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><g><rect x="83.534" y="40.929" width="3.997" height="20.071"/></g><path d="M16.466,41.931l33.548-25.123L92.81,48.877l2.396-3.198L50.015,11.814L4.794,45.679l2.396,3.199l5.279-3.954v42.763h75.062  V61h-3.997v22.69H64.598V54.068H35.402V83.69H16.466V41.931z M39.399,58.065h21.202V83.69H39.399V58.065z"/></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="../../archive.html">
              <div class="left">
                All Posts
              </div>
              <div class="right">
                <svg width="24px" aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="-3 3 64 64"><g><path d="M60.992,31.985c0-15.979-13-28.978-28.979-28.978c-15.994,0-29.006,12.999-29.006,28.978   c0,15.994,13.012,29.007,29.006,29.007v-2c-14.891,0-27.006-12.115-27.006-27.007c0-14.875,12.115-26.978,27.006-26.978   c14.876,0,26.979,12.103,26.979,26.978c0,8.945-4.479,17.329-11.804,22.338l0.874-10.062l-1.992-0.174l-1.135,13.071l13.042,1.136   l0.174-1.992l-9.183-0.799C56.443,50.079,60.992,41.321,60.992,31.985z"/><polygon points="33.014,12.682 31.014,12.682 31.014,32.398 39.811,41.224 41.227,39.812 33.014,31.572  "/></g></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="../../about.html">
              <div class="left">
                About me
              </div>
              <div class="right">
                <svg width='24px' aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 846.66 846.66"><g><path d="M351.26 453.22c-276.42,134.06 -224.86,336.22 -224.73,336.8 6.03,25.41 -32.58,34.56 -38.6,9.15 -0.15,-0.65 -55.78,-219.32 218.87,-367.66 -60.98,-39 -100.02,-106.82 -100.02,-182.56 0,-119.6 96.95,-216.55 216.55,-216.55 119.6,0 216.55,96.95 216.55,216.55 0,75.74 -39.04,143.56 -100.02,182.56 274.65,148.34 219.02,367.01 218.87,367.66 -6.02,25.41 -44.63,16.26 -38.6,-9.15 0.13,-0.58 51.69,-202.74 -224.73,-336.8 -22.55,7.96 -46.8,12.29 -72.07,12.29 -25.27,0 -49.52,-4.33 -72.07,-12.29zm72.07 -381.14c-97.68,0 -176.87,79.19 -176.87,176.87 0,97.69 79.19,176.87 176.87,176.87 97.68,0 176.87,-79.18 176.87,-176.87 0,-97.68 -79.19,-176.87 -176.87,-176.87z"/></g></svg>
              </div>
            </a>
          </li>
          <li>
            <a href="../../resume.html">
              <div class="left">
                Resume
              </div>
              <div class="right">
                <!-- Add the SVG icon for Resume -->
              <svg height="24px" width="24px" viewBox="0 0 60 60" xmlns="http://www.w3.org/2000/svg" fill="currentColor">
                <g>
                  <path d="M38.914,0H6.5v60h47V14.586L38.914,0z M39.5,3.414L50.086,14H39.5V3.414z M8.5,58V2h29v14h14v42H8.5z"/>
                  <path d="M34.5,37c0.552,0,1-0.447,1-1s-0.448-1-1-1h-17c-0.552,0-1,0.447-1,1s0.448,1,1,1H34.5z"/>
                  <path d="M44.5,30h-7c-0.552,0-1,0.447-1,1s0.448,1,1,1h7c0.552,0,1-0.447,1-1S45.052,30,44.5,30z"/>
                  <path d="M21.5,31c0,0.553,0.448,1,1,1h10c0.552,0,1-0.447,1-1s-0.448-1-1-1h-10C21.948,30,21.5,30.447,21.5,31z"/>
                  <path d="M16.79,30.29c-0.18,0.189-0.29,0.449-0.29,0.71c0,0.26,0.11,0.52,0.29,0.7c0.18,0.189,0.44,0.3,0.71,0.3
                    s0.52-0.11,0.71-0.29c0.18-0.19,0.29-0.45,0.29-0.71c0-0.261-0.11-0.521-0.29-0.71C17.84,29.92,17.15,29.93,16.79,30.29z"/>
                  <path d="M38.79,35.29c-0.18,0.189-0.29,0.439-0.29,0.71c0,0.27,0.1,0.52,0.29,0.71C38.98,36.89,39.24,37,39.5,37
                    c0.26,0,0.52-0.11,0.71-0.29c0.19-0.19,0.29-0.44,0.29-0.71c0-0.261-0.11-0.521-0.29-0.71C39.83,34.92,39.17,34.92,38.79,35.29z"/>
                  <path d="M43.79,35.29c-0.18,0.189-0.29,0.439-0.29,0.71c0,0.27,0.1,0.52,0.29,0.71C43.98,36.89,44.24,37,44.5,37
                    c0.26,0,0.52-0.11,0.71-0.3c0.19-0.19,0.29-0.44,0.29-0.7c0-0.261-0.11-0.521-0.29-0.71C44.83,34.92,44.17,34.92,43.79,35.29z"/>
                  <path d="M23.025,40.166c-2.19,1.14-2.927,3.321-3.196,5.582c-0.414-0.347-0.828-0.693-1.242-1.04
                    c-0.98-0.821-2.402,0.586-1.414,1.415c0.935,0.783,1.871,1.567,2.806,2.351c0.658,0.551,1.676,0.203,1.707-0.707
                    c0.073-2.166,0.175-4.742,2.348-5.873C25.177,41.299,24.166,39.572,23.025,40.166z"/>
                  <path d="M36.455,44.108c-1.458-0.092-3.592,2.155-4.716,0.153c-0.26-0.464-0.913-0.638-1.368-0.359
                      c-1.416,0.869-3.267,2.119-4.756,0.5c-0.873-0.949-2.285,0.468-1.414,1.414c1.87,2.033,4.276,1.415,6.399,0.263
                      c0.478,0.535,1.071,0.926,1.837,1.081c0.792,0.16,4.025-1.141,4.2-0.901c0.752,1.029,2.488,0.032,1.727-1.009
                      C37.847,44.543,37.371,44.166,36.455,44.108z"/>
                  <path d="M28.666,23.963l0.674-0.479l-0.344-0.752c-0.312-0.682-0.813-1.212-1.45-1.532l-2.12-1.082
                    c0.975-0.623,1.676-1.561,2.095-2.801c0.684-0.417,1.115-1.158,1.115-1.984v-0.667c0-0.677-0.294-1.308-0.794-1.745
                    c-0.357-1.898-1.644-3.951-5.54-3.951c-0.153,0-0.303,0.006-0.451,0.018c-0.523,0.043-1.285,0-1.937-0.438
                    c-0.303-0.204-0.458-0.362-0.534-0.459c-0.317-0.403-0.849-0.544-1.324-0.35c-0.474,0.195-0.752,0.669-0.694,1.179
                    c0.03,0.257,0.073,0.557,0.138,0.884c0.084,0.42,0.089,0.541,0.086,0.573c-0.008,0.035-0.066,0.159-0.112,0.259
                    c-0.07,0.15-0.156,0.335-0.257,0.582c-0.217,0.529-0.375,1.105-0.471,1.719c-0.489,0.438-0.778,1.063-0.778,1.73v0.667
                    c0,0.826,0.431,1.567,1.115,1.984c0.417,1.235,1.115,2.171,2.083,2.793l-2.204,1.087c-0.613,0.334-1.091,0.867-1.382,1.541
                    l-0.32,0.741l0.656,0.469C17.797,25.291,20.004,26,22.302,26C24.592,26,26.792,25.296,28.666,23.963z M18.016,22.907l2.445-1.204
                    c0.519-0.257,0.842-0.776,0.842-1.355v-1.422l-0.604-0.261c-0.912-0.392-1.506-1.151-1.819-2.321l-0.143-0.533l-0.527-0.164
                    c-0.116-0.036-0.24-0.149-0.24-0.313v-0.667c0-0.142,0.095-0.242,0.184-0.289l0.469-0.25l0.055-0.529
                    c0.062-0.595,0.193-1.14,0.391-1.622c0.086-0.211,0.16-0.368,0.22-0.497c0.155-0.332,0.249-0.578,0.283-0.855
                    c0.73,0.305,1.559,0.425,2.44,0.358c0.095-0.008,0.192-0.012,0.291-0.012c2.919,0,3.469,1.334,3.622,2.638l0.061,0.523l0.466,0.245
                    c0.089,0.047,0.185,0.147,0.185,0.29v0.667c0,0.164-0.125,0.277-0.24,0.313l-0.527,0.164l-0.143,0.533
                    c-0.313,1.17-0.908,1.93-1.819,2.321l-0.604,0.261v1.428c0,0.57,0.315,1.086,0.825,1.347l2.415,1.233
                    C23.923,24.343,20.628,24.334,18.016,22.907z"/>
                  </g>
                </svg>
              </div>
            </a>
          </li>
        </ul>
      </nav>
      
      
      <div class="logo"><a href="../../"><img class="logo" id="logo" src="../../assets/img/branding/logo-full.svg" alt="Tropical Insights"></a></div>
      <div class="search-icon-container">
        <span class="search-icon"><a><i class="fa fa-search" aria-hidden="true"></i></a></span>
      </div>
    </div>
  </div>
</header> <!-- End Header -->

  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Neural Network Optimization Methods and Algorithms">
<meta itemprop="description" content="Some neural network optimization algorithms mostly to implement momentum when doing back propagation.">
<meta itemprop="datePublished" content="2021-03-12T14:32:20-05:00">

    <div class="page-image">
      <div class="cover-image" style="background: url('../../assets/img/posts/20210312/nnet_optimization.jpg') center no-repeat; background-size: cover;"></div>
    </div>
    <div class="wrapper">
      <div class="page-content">
        <div class="header-page">
          <h1 class="page-title">Neural Network Optimization Methods and Algorithms</h1>
          

  <span class = "post-page-meta">
  
    <p class="page_meta">
  
  
  
    
      
      <span class="page_meta-date">
        <time datetime="2021-03-12T14:32:20-05:00">March 12, 2021</time>
      </span>
    
    
      <span class="meta-sep"></span>
    
  
  
    
    
    <span class="page_meta-readtime">
      
        8 minute read
      
    </span>
  
  
    </p>
  
  </span>

        </div>
        <aside class="sidebar side" id="sidebar">
    



<div class="tag-cloud">
    
        <ul class="tags side">
            
                <li><a href="../../tag.html?tag=coding" class="tag side">coding</a></li>
            
                <li><a href="../../tag.html?tag=machine+learning" class="tag side">machine learning</a></li>
            
                <li><a href="../../tag.html?tag=optimization" class="tag side">optimization</a></li>
            
                <li><a href="../../tag.html?tag=deep+Neural+networks" class="tag side">deep Neural networks</a></li>
            
    
        </ul>
</div>
    <div class="share-options side">
    <div class="share-hover side">
        <span class="share-button side"><svg fill="currentColor" width="25" height="25" class="side"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></span>
        <div class="share-icons side" id="sidebar-icons">
            <a class="twitter" href="https://twitter.com/intent/tweet?text=Neural Network Optimization Methods and Algorithms&url=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html" title="Share on Twitter" rel="nofollow" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
            <a class="facebook" href="https://facebook.com/sharer.php?u=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html" title="Share on Facebook" rel="nofollow" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
            <a class="reddit" href="http://www.reddit.com/submit?url=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html&title=Neural Network Optimization Methods and Algorithms" title="Submit to Reddit" rel="nofollow" target="_blank"><i class="fa fa-reddit" aria-hidden="true"></i></a>
            <a class="linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html&title=Neural Network Optimization Methods and Algorithms&summary=Some neural network optimization algorithms mostly to implement momentum when doing back propagation.&source=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html" title="Share on LinkedIn" rel="nofollow" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
            <a class="email" href="mailto:?subject=Neural Network Optimization Methods and Algorithms&body=Some neural network optimization algorithms mostly to implement momentum when doing back propagation.%0A%0ARead more here: http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html" title="Share via e-mail" rel="nofollow" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
            <a class="copy-link" onclick="copyToClipboard()" title="Copy to clipboard" rel="nofollow" target="_blank"><svg width="20px" fill="currentColor" class="side" viewBox="0 0 18 18"><path d="M16.94 1.1A3.7 3.7 0 0 0 14.3 0c-1 0-1.94.39-2.64 1.1L7.43 5.3c-.91.92-2.09 3.2 0 5.27a.75.75 0 0 0 .82.16c.09-.03.17-.09.24-.15a.74.74 0 0 0 0-1.06c-1.16-1.15-.77-2.39-.02-3.16l4.24-4.22a2.2 2.2 0 0 1 1.58-.65c.6 0 1.16.23 1.58.65.86.87.86 2.29 0 3.16L12.7 8.47a.74.74 0 0 0 1.04 1.05l3.17-3.16a3.73 3.73 0 0 0 0-5.27h.03zM9.54 7.4a.74.74 0 0 0 0 1.06c1.16 1.15.76 2.39 0 3.16l-4.22 4.22c-.42.42-.99.65-1.59.65a2.23 2.23 0 0 1-1.58-3.82l3.17-3.16A.73.73 0 0 0 5.54 9a.78.78 0 0 0-.22-.52.77.77 0 0 0-1.05 0L1.1 11.64A3.72 3.72 0 0 0 3.74 18c1 0 1.94-.39 2.65-1.1l4.23-4.2c.21-.22.94-1.02 1.13-2.2.18-1.12-.2-2.15-1.12-3.07-.27-.27-.78-.27-1.06 0l-.02-.02z" clip-rule="evenodd" fill-rule="evenodd"></path></svg></a>
        </div>
    </div>
    <div class='alert' style='font-size:.6em;color:var(--accent);text-align:center;'></div>
</div>
</aside>

        <aside class="toc">
  <nav class="toc-nav">
    <li class="toc-title">
      <svg aria-hidden="true" focusable="false" data-prefix="fad" data-icon="align-left" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="svg-inline--fa fa-align-left fa-w-14 fa-2x"><g class="fa-group"><path fill="currentColor" d="M12.83 352h262.34A12.82 12.82 0 0 0 288 339.17v-38.34A12.82 12.82 0 0 0 275.17 288H12.83A12.82 12.82 0 0 0 0 300.83v38.34A12.82 12.82 0 0 0 12.83 352zm0-256h262.34A12.82 12.82 0 0 0 288 83.17V44.83A12.82 12.82 0 0 0 275.17 32H12.83A12.82 12.82 0 0 0 0 44.83v38.34A12.82 12.82 0 0 0 12.83 96z" class="fa-secondary"></path><path fill="currentColor" d="M432 160H16a16 16 0 0 0-16 16v32a16 16 0 0 0 16 16h416a16 16 0 0 0 16-16v-32a16 16 0 0 0-16-16zm0 256H16a16 16 0 0 0-16 16v32a16 16 0 0 0 16 16h416a16 16 0 0 0 16-16v-32a16 16 0 0 0-16-16z" class="fa-primary"></path></g></svg>
    </li>
    <ul class="toc-content" id="toc-content"><li class="toc-item-1"><a href="#adam">Adam</a></li><li class="toc-item-1"><a href="#sgd-momentum">SGD Momentum</a></li><li class="toc-item-1"><a href="#nesterov-accelerated-gradient-nag">Nesterov accelerated gradient (NAG)</a></li><li class="toc-item-1"><a href="#rmsprop">RMSprop</a></li><li class="toc-item-1"><a href="#complete-code">Complete code</a></li></ul>
  </nav>
</aside>

        
<div class="center-container">
  <div class="github-button">
    <span class="button-icon" aria-hidden="true"><svg aria-hidden="true" focusable="false" role="img" fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12,2.2467A10.00042,10.00042,0,0,0,8.83752,21.73419c.5.08752.6875-.21247.6875-.475,0-.23749-.01251-1.025-.01251-1.86249C7,19.85919,6.35,18.78423,6.15,18.22173A3.636,3.636,0,0,0,5.125,16.8092c-.35-.1875-.85-.65-.01251-.66248A2.00117,2.00117,0,0,1,6.65,17.17169a2.13742,2.13742,0,0,0,2.91248.825A2.10376,2.10376,0,0,1,10.2,16.65923c-2.225-.25-4.55-1.11254-4.55-4.9375a3.89187,3.89187,0,0,1,1.025-2.6875,3.59373,3.59373,0,0,1,.1-2.65s.83747-.26251,2.75,1.025a9.42747,9.42747,0,0,1,5,0c1.91248-1.3,2.75-1.025,2.75-1.025a3.59323,3.59323,0,0,1,.1,2.65,3.869,3.869,0,0,1,1.025,2.6875c0,3.83747-2.33752,4.6875-4.5625,4.9375a2.36814,2.36814,0,0,1,.675,1.85c0,1.33752-.01251,2.41248-.01251,2.75,0,.26251.1875.575.6875.475A10.0053,10.0053,0,0,0,12,2.2467Z"/></svg></span>
    <a class="button-text" href="https://github.com/amaynez/TicTacToe/blob/7bf83b3d5c10adccbeb11bf244fe0af8d9d7b036/entities/Neural_Network.py#L199" target="_blank" aria-label="Open on GitHub">view on <b>GitHub</b></a>
  </div>
</div>

        <p>For the seemingly small project I undertook of <a href="./deep-q-learning-tic-tac-toe.html">creating a machine learning neural network that could learn by itself to play tic-tac-toe</a>, I bumped into the necesity of implementing at least one momentum algorithm for the optimization of the network during backpropagation.</p>

<p>And since my original post for the TicTacToe project is quite large already, I decided to post separately these optimization methods and how did I implement them in my code.</p>

<h3 id="adam">Adam</h3>
<p><a href="https://ruder.io/optimizing-gradient-descent/index.html#adam">source</a></p>

<p>Adaptive Moment Estimation (Adam) is an optimization method that computes adaptive learning rates for each weight and bias. In addition to storing an exponentially decaying average of past squared gradients \(v_t\) and an exponentially decaying average of past gradients \(m_t\), similar to momentum. Whereas momentum can be seen as a ball running down a slope, Adam behaves like a heavy ball with friction, which thus prefers flat minima in the error surface. We compute the decaying averages of past and past squared gradients \(m_t\) and \(v_t\) respectively as follows:</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
m_t &amp;= \beta_1 m_{t-1} + (1 - \beta_1) g_t \\<br />
v_t &amp;= \beta_2 v_{t-1} + (1 - \beta_2) g_t^2<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>\(m_t\) and \(v_t\) are estimates of the first moment (the mean) and the second moment (the uncentered variance) of the gradients respectively, hence the name of the method. As \(m_t\) and \(v_t\) are initialized as vectors of 0's, the authors of Adam observe that they are biased towards zero, especially during the initial time steps, and especially when the decay rates are small (i.e. \(\beta_1\) and \(\beta_2\) are close to 1).</p>
<p>They counteract these biases by computing bias-corrected first and second moment estimates:</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
\hat{m}_t &amp;= \dfrac{m_t}{1 - \beta^t_1} \\<br />
\hat{v}_t &amp;= \dfrac{v_t}{1 - \beta^t_2} \end{split}<br />
\end{align}<br />
\)</p>
<p>We then use these to update the weights and biases which yields the Adam update rule:</p>
<p style="text-align:center">\(\theta_{t+1} = \theta_{t} - \dfrac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t\).</p>
<p>The authors propose defaults of 0.9 for \(\beta_1\), 0.999 for \(\beta_2\), and \(10^{-8}\) for \(\epsilon\).</p>
<p><a href="https://github.com/amaynez/TicTacToe/blob/b429e5637fe5f61e997f04c01422ad0342565640/entities/Neural_Network.py#L243">view on github</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># decaying averages of past gradients
</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                        <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                        <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span>
                        <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                        <span class="p">))</span>
<span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                        <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                        <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span>
                        <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                        <span class="p">))</span>

<span class="c1"># decaying averages of past squared gradients
</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA2</span>
                        <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                        <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA2</span><span class="p">)</span>
                        <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                         <span class="p">))</span>
<span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA2</span>
                        <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                        <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA2</span><span class="p">)</span>
                        <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span>
                                         <span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                         <span class="p">))</span>

<span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">ADAM_BIAS_Correction</span><span class="p">:</span>
    <span class="c1"># bias-corrected first and second moment estimates
</span>    <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                          <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span> <span class="o">**</span> <span class="n">true_epoch</span><span class="p">))</span>
    <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                          <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span> <span class="o">**</span> <span class="n">true_epoch</span><span class="p">))</span>
    <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                          <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">BETA2</span> <span class="o">**</span> <span class="n">true_epoch</span><span class="p">))</span>
    <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                          <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">BETA2</span> <span class="o">**</span> <span class="n">true_epoch</span><span class="p">))</span>

<span class="c1"># apply to weights and biases
</span><span class="n">weight_col</span> <span class="o">-=</span> <span class="p">((</span><span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                      <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                      <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">EPSILON</span><span class="p">))))</span>
<span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="p">((</span><span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                        <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                        <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">EPSILON</span><span class="p">))))</span>
</code></pre></div></div>

<h3 id="sgd-momentum">SGD Momentum</h3>
<p><a href="https://ruder.io/optimizing-gradient-descent/index.html#momentum">source</a></p>

<p>Vanilla SGD has trouble navigating ravines, i.e. areas where the surface curves much more steeply in one dimension than in another, which are common around local optima. In these scenarios, SGD oscillates across the slopes of the ravine while only making hesitant progress along the bottom towards the local optimum.</p>
<p>Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations. It does this by adding a fraction \(\gamma\) of the update vector of the past time step to the current update vector:</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
v_t &amp;= \beta_1 v_{t-1} + \eta \nabla_\theta J( \theta) \\<br />
\theta &amp;= \theta - v_t<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>The momentum term \(\beta_1\) is usually set to 0.9 or a similar value.</p>
<p>Essentially, when using momentum, we push a ball down a hill. The ball accumulates momentum as it rolls downhill, becoming faster and faster on the way (until it reaches its terminal velocity if there is air resistance, i.e. \(\beta_1 &lt; 1\)). The same thing happens to our weight and biases updates: The momentum term increases for dimensions whose gradients point in the same directions and reduces updates for dimensions whose gradients change directions. As a result, we gain faster convergence and reduced oscillation.</p>
<p><a href="https://github.com/amaynez/TicTacToe/blob/b429e5637fe5f61e997f04c01422ad0342565640/entities/Neural_Network.py#L210">view on github</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                       <span class="o">+</span><span class="p">(</span><span class="n">eta</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                       <span class="p">))</span>
<span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                       <span class="o">+</span><span class="p">(</span><span class="n">eta</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                       <span class="p">))</span>

<span class="n">weight_col</span> <span class="o">-=</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
<span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
</code></pre></div></div>

<h3 id="nesterov-accelerated-gradient-nag">Nesterov accelerated gradient (NAG)</h3>
<p><a href="https://ruder.io/optimizing-gradient-descent/index.html#nesterovacceleratedgradient">source</a></p>

<p>However, a ball that rolls down a hill, blindly following the slope, is highly unsatisfactory. We'd like to have a smarter ball, a ball that has a notion of where it is going so that it knows to slow down before the hill slopes up again.</p>
<p>Nesterov accelerated gradient (NAG) is a way to give our momentum term this kind of prescience. We know that we will use our momentum term \(\beta_1 v_{t-1}\) to move the weights and biases \(\theta\). Computing \( \theta - \beta_1 v_{t-1} \) thus gives us an approximation of the next position of the weights and biases (the gradient is missing for the full update), a rough idea where our weights and biases are going to be. We can now effectively look ahead by calculating the gradient not w.r.t. to our current weights and biases \(\theta\) but w.r.t. the approximate future position of our weights and biases:</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
v_t &amp;= \beta_1 v_{t-1} + \eta \nabla_\theta J( \theta - \beta_1 v_{t-1} ) \\<br />
\theta &amp;= \theta - v_t<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>Again, we set the momentum term \(\beta_1\) to a value of around 0.9. While Momentum first computes the current gradient and then takes a big jump in the direction of the updated accumulated gradient, NAG first makes a big jump in the direction of the previous accumulated gradient, measures the gradient and then makes a correction, which results in the complete NAG update. This anticipatory update prevents us from going too fast and results in increased responsiveness, which has significantly increased the performance of Neural Networks on a number of tasks.</p>
<p>Now that we are able to adapt our updates to the slope of our error function and speed up SGD in turn, we would also like to adapt our updates to each individual weight and bias to perform larger or smaller updates depending on their importance.</p>
<p><a href="https://github.com/amaynez/TicTacToe/blob/b429e5637fe5f61e997f04c01422ad0342565640/entities/Neural_Network.py#L219">view on github</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">v_prev</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">):</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)],</span>
          <span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">):</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]}</span>

<span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
            <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">NAG_COEFF</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
           <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
<span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
            <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">NAG_COEFF</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
           <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="n">weight_col</span> <span class="o">+=</span> <span class="p">((</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span> <span class="o">*</span> <span class="n">v_prev</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
               <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
<span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">((</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span> <span class="o">*</span> <span class="n">v_prev</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
               <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
</code></pre></div></div>

<h3 id="rmsprop">RMSprop</h3>
<p><a href="https://ruder.io/optimizing-gradient-descent/index.html#rmsprop">source</a></p>

<p>RMSprop is an unpublished, adaptive learning rate method proposed by Geoff Hinton in <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">Lecture 6e of his Coursera Class</a>.</p>
<p>RMSprop was developed stemming from the need to resolve other method's radically diminishing learning rates.</p>
<p style="text-align:center">\(<br />
\begin{align}<br />
\begin{split}<br />
E[\theta^2]_t &amp;= \beta_1 E[\theta^2]_{t-1} + (1-\beta_1) \theta^2_t \\<br />
\theta_{t+1} &amp;= \theta_{t} - \dfrac{\eta}{\sqrt{E[\theta^2]_t + \epsilon}} \theta_{t}<br />
\end{split}<br />
\end{align}<br />
\)</p>
<p>RMSprop divides the learning rate by an exponentially decaying average of squared gradients. Hinton suggests \(\beta_1\) to be set to 0.9, while a good default value for the learning rate \(\eta\) is 0.001.</p>
<p><a href="https://github.com/amaynez/TicTacToe/blob/b429e5637fe5f61e997f04c01422ad0342565640/entities/Neural_Network.py#L232">view on github</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                      <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                      <span class="o">+</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span>
                      <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                        <span class="p">))</span>
<span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                      <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                      <span class="o">+</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span>
                      <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                        <span class="p">))</span>

<span class="n">weight_col</span> <span class="o">-=</span> <span class="p">(</span><span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
              <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span><span class="o">+</span><span class="n">c</span><span class="p">.</span><span class="n">EPSILON</span><span class="p">)))</span>
              <span class="p">)</span>
<span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span><span class="n">eta</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
               <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span><span class="o">+</span><span class="n">c</span><span class="p">.</span><span class="n">EPSILON</span><span class="p">)))</span>
                <span class="p">)</span>
</code></pre></div></div>

<h3 id="complete-code">Complete code</h3>
<p>All in all the code ended up like this:
<a href="https://github.com/amaynez/TicTacToe/blob/b429e5637fe5f61e997f04c01422ad0342565640/entities/Neural_Network.py#L1">view on github</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@staticmethod</span>
<span class="k">def</span> <span class="nf">cyclic_learning_rate</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">max_lr</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">c</span><span class="p">.</span><span class="n">MAX_LR_FACTOR</span>
    <span class="n">cycle</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">floor</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span>
                    <span class="o">*</span> <span class="n">c</span><span class="p">.</span><span class="n">LR_STEP_SIZE</span><span class="p">))</span>
                    <span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">((</span><span class="n">epoch</span> <span class="o">/</span> <span class="n">c</span><span class="p">.</span><span class="n">LR_STEP_SIZE</span><span class="p">)</span>
        <span class="o">-</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">cycle</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">learning_rate</span>
        <span class="o">+</span> <span class="p">(</span><span class="n">max_lr</span> <span class="o">-</span> <span class="n">learning_rate</span><span class="p">)</span>
        <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">apply_gradients</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">true_epoch</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BATCH_SIZE</span>
    <span class="n">eta</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span>
            <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">DECAY_RATE</span> <span class="o">*</span> <span class="n">true_epoch</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">CLR_ON</span><span class="p">:</span>
        <span class="n">eta</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">cyclic_learning_rate</span><span class="p">(</span><span class="n">eta</span><span class="p">,</span> <span class="n">true_epoch</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">weight_col</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">):</span>

        <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">OPTIMIZATION</span> <span class="o">==</span> <span class="sh">'</span><span class="s">vanilla</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">weight_col</span> <span class="o">-=</span> <span class="n">eta</span>
                        <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                        <span class="o">/</span> <span class="n">c</span><span class="p">.</span><span class="n">BATCH_SIZE</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">eta</span>
                        <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                        <span class="o">/</span> <span class="n">c</span><span class="p">.</span><span class="n">BATCH_SIZE</span>

        <span class="k">elif</span> <span class="n">c</span><span class="p">.</span><span class="n">OPTIMIZATION</span> <span class="o">==</span> <span class="sh">'</span><span class="s">SGD_momentum</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                                   <span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                                   <span class="o">+</span><span class="p">(</span><span class="n">eta</span>
                                   <span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                                   <span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                                   <span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                                   <span class="o">+</span><span class="p">(</span><span class="n">eta</span>
                                   <span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                                   <span class="p">))</span>

            <span class="n">weight_col</span> <span class="o">-=</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>

        <span class="k">elif</span> <span class="n">c</span><span class="p">.</span><span class="n">OPTIMIZATION</span> <span class="o">==</span> <span class="sh">'</span><span class="s">NAG</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">v_prev</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">):</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)],</span>
                      <span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">):</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]}</span>

            <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
                        <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">NAG_COEFF</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                       <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
                        <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">NAG_COEFF</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                       <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

            <span class="n">weight_col</span> <span class="o">+=</span> <span class="p">((</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span> <span class="o">*</span> <span class="n">v_prev</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                           <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">((</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span> <span class="o">*</span> <span class="n">v_prev</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                           <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span> <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>

        <span class="k">elif</span> <span class="n">c</span><span class="p">.</span><span class="n">OPTIMIZATION</span> <span class="o">==</span> <span class="sh">'</span><span class="s">RMSProp</span><span class="sh">'</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
                            <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                            <span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                            <span class="o">+</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span>
                            <span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                            <span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
                            <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                            <span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                            <span class="o">+</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span>
                            <span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                            <span class="p">))</span>

            <span class="n">weight_col</span> <span class="o">-=</span> <span class="p">(</span><span class="n">eta</span>
                          <span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                          <span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span><span class="o">+</span><span class="n">c</span><span class="p">.</span><span class="n">EPSILON</span><span class="p">)))</span>
                          <span class="p">)</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span><span class="n">eta</span>
                          <span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                          <span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span><span class="o">+</span><span class="n">c</span><span class="p">.</span><span class="n">EPSILON</span><span class="p">)))</span>
                            <span class="p">)</span>

        <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">OPTIMIZATION</span> <span class="o">==</span> <span class="sh">"</span><span class="s">ADAM</span><span class="sh">"</span><span class="p">:</span>
            <span class="c1"># decaying averages of past gradients
</span>            <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span>
                                <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                              <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                              <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span>
                              <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                                    <span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span>
                                <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span>
                              <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                              <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA1</span><span class="p">)</span>
                              <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                                    <span class="p">))</span>

            <span class="c1"># decaying averages of past squared gradients
</span>            <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA2</span>
                                    <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span><span class="o">+</span><span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                                    <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA2</span><span class="p">)</span>
                                    <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span>
                                            <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span>
                                                <span class="n">self</span><span class="p">.</span><span class="n">gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                                     <span class="p">))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="p">((</span><span class="n">c</span><span class="p">.</span><span class="n">BETA2</span>
                                    <span class="o">*</span> <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                                    <span class="o">+</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">c</span><span class="p">.</span><span class="n">BETA2</span><span class="p">)</span>
                                    <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span>
                                            <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span>
                                                <span class="n">self</span><span class="p">.</span><span class="n">bias_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
                                     <span class="p">))</span>

            <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="n">ADAM_BIAS_Correction</span><span class="p">:</span>
                <span class="c1"># bias-corrected first and second moment estimates
</span>                <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
                                <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                              <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span> <span class="o">**</span> <span class="n">true_epoch</span><span class="p">))</span>
                <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
                                <span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                              <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">BETA1</span> <span class="o">**</span> <span class="n">true_epoch</span><span class="p">))</span>
                <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
                                <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                              <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">BETA2</span> <span class="o">**</span> <span class="n">true_epoch</span><span class="p">))</span>
                <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span>
                                <span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                              <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">BETA2</span> <span class="o">**</span> <span class="n">true_epoch</span><span class="p">))</span>

            <span class="c1"># apply to weights and biases
</span>            <span class="n">weight_col</span> <span class="o">-=</span> <span class="p">((</span><span class="n">eta</span>
                            <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                            <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">dW</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                            <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">EPSILON</span><span class="p">))))</span>
            <span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="p">((</span><span class="n">eta</span>
                            <span class="o">*</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">v</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
                            <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">s</span><span class="p">[</span><span class="sh">"</span><span class="s">db</span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">i</span><span class="p">)])</span>
                            <span class="o">+</span> <span class="n">c</span><span class="p">.</span><span class="n">EPSILON</span><span class="p">))))</span>

    <span class="n">self</span><span class="p">.</span><span class="nf">gradient_zeros</span><span class="p">()</span>
</code></pre></div></div>


        <aside class="sidebar inline" id="post-end">
    



<div class="tag-cloud">
    
        <ul class="tags inline">
            
                <li><a href="../../tag.html?tag=coding" class="tag inline">coding</a></li>
            
                <li><a href="../../tag.html?tag=machine+learning" class="tag inline">machine learning</a></li>
            
                <li><a href="../../tag.html?tag=optimization" class="tag inline">optimization</a></li>
            
                <li><a href="../../tag.html?tag=deep+Neural+networks" class="tag inline">deep Neural networks</a></li>
            
    
        </ul>
</div>
    <div class="share-options inline">
    <div class="share-hover inline">
        <span class="share-button inline"><svg fill="currentColor" width="25" height="25" class="inline"><g fill-rule="evenodd"><path d="M15.6 5a.42.42 0 0 0 .17-.3.42.42 0 0 0-.12-.33l-2.8-2.79a.5.5 0 0 0-.7 0l-2.8 2.8a.4.4 0 0 0-.1.32c0 .12.07.23.16.3h.02a.45.45 0 0 0 .57-.04l2-2V10c0 .28.23.5.5.5s.5-.22.5-.5V2.93l2.02 2.02c.08.07.18.12.3.13.11.01.21-.02.3-.08v.01"></path><path d="M18 7h-1.5a.5.5 0 0 0 0 1h1.6c.5 0 .9.4.9.9v10.2c0 .5-.4.9-.9.9H6.9a.9.9 0 0 1-.9-.9V8.9c0-.5.4-.9.9-.9h1.6a.5.5 0 0 0 .35-.15A.5.5 0 0 0 9 7.5a.5.5 0 0 0-.15-.35A.5.5 0 0 0 8.5 7H7a2 2 0 0 0-2 2v10c0 1.1.9 2 2 2h11a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2"></path></g></svg></span>
        <div class="share-icons inline" id="post-end-icons">
            <a class="twitter" href="https://twitter.com/intent/tweet?text=Neural Network Optimization Methods and Algorithms&url=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html" title="Share on Twitter" rel="nofollow" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
            <a class="facebook" href="https://facebook.com/sharer.php?u=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html" title="Share on Facebook" rel="nofollow" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
            <a class="reddit" href="http://www.reddit.com/submit?url=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html&title=Neural Network Optimization Methods and Algorithms" title="Submit to Reddit" rel="nofollow" target="_blank"><i class="fa fa-reddit" aria-hidden="true"></i></a>
            <a class="linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html&title=Neural Network Optimization Methods and Algorithms&summary=Some neural network optimization algorithms mostly to implement momentum when doing back propagation.&source=http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html" title="Share on LinkedIn" rel="nofollow" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
            <a class="email" href="mailto:?subject=Neural Network Optimization Methods and Algorithms&body=Some neural network optimization algorithms mostly to implement momentum when doing back propagation.%0A%0ARead more here: http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html" title="Share via e-mail" rel="nofollow" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
            <a class="copy-link" onclick="copyToClipboard()" title="Copy to clipboard" rel="nofollow" target="_blank"><svg width="20px" fill="currentColor" class="inline" viewBox="0 0 18 18"><path d="M16.94 1.1A3.7 3.7 0 0 0 14.3 0c-1 0-1.94.39-2.64 1.1L7.43 5.3c-.91.92-2.09 3.2 0 5.27a.75.75 0 0 0 .82.16c.09-.03.17-.09.24-.15a.74.74 0 0 0 0-1.06c-1.16-1.15-.77-2.39-.02-3.16l4.24-4.22a2.2 2.2 0 0 1 1.58-.65c.6 0 1.16.23 1.58.65.86.87.86 2.29 0 3.16L12.7 8.47a.74.74 0 0 0 1.04 1.05l3.17-3.16a3.73 3.73 0 0 0 0-5.27h.03zM9.54 7.4a.74.74 0 0 0 0 1.06c1.16 1.15.76 2.39 0 3.16l-4.22 4.22c-.42.42-.99.65-1.59.65a2.23 2.23 0 0 1-1.58-3.82l3.17-3.16A.73.73 0 0 0 5.54 9a.78.78 0 0 0-.22-.52.77.77 0 0 0-1.05 0L1.1 11.64A3.72 3.72 0 0 0 3.74 18c1 0 1.94-.39 2.65-1.1l4.23-4.2c.21-.22.94-1.02 1.13-2.2.18-1.12-.2-2.15-1.12-3.07-.27-.27-.78-.27-1.06 0l-.02-.02z" clip-rule="evenodd" fill-rule="evenodd"></path></svg></a>
        </div>
    </div>
    <div class='alert' style='font-size:.6em;color:var(--accent);text-align:center;'></div>
</div>
</aside>

        <div class="separator"></div>
        



<section class="author-box">
  <div class="narrow-column">
    <a href='https://www.heiricar.com'><img src="../../assets/img/Myself.jpg" alt="Hernan Iriarte" class="author-img"></a>
    <ul class="contact-icons">
      
      
      <li class="linkedin"><a class="linkedin" href="https://in.linkedin.com/in/hernan-iriarte" target="_blank"><i class="fa fa-linkedin"></i></a></li>
      
      
      <li class="github"><a class="github" href="http://github.com/heiricar" target="_blank"><i class="fa fa-github"></i></a></li>
      
      
      <li class="email"><a class="email" href="mailto:heiricar@gmail.com"><i class="fa fa-envelope-o"></i></a></li>
      
      
    </ul>
  </div>
  <div class="author-desc">
    <h3>Hernan Iriarte</h3>
    <p>I hold a PhD in Mathematics from cole Polytechnique and have conducted postdoctoral research at the University of Texas at Austin, where I also served as a lecturer. I'm an avid learner with diverse interests spanning pure and applied mathematics, economics, computer science, and artificial intelligence.</p>
  </div>
</section>

        



<div class="recent-box">
  <h2 class="page-subtitle">Recent posts</h2>
  <div class="recent-list">
    
      
        <div class="recent-item">
          
          

          <a href="../../test.html" class="recent-item-img" style="background: url('../../assets/img/posts/post1.jpg') center no-repeat; background-size: cover;">
            <div class="recent-item-title">
              <span>The mutual fund theorem</span>
              

  <span class = "recent-item-meta">
  
  
  
  
    
    
    <p class="page_meta-readtime">
      
        less than 1 minute read
      
    </p>
  
  
  </span>

            </div>
          </a>
        </div>
      
    
  </div>
</div> <!-- End Recent-Box -->

        <div class="newsletter" id="mc_embed_signup">
  <h2 class="page-subtitle">Newsletter</h2>
  <div class="form-container">
    <p>Subscribe here to get our latest updates</p>
    <form action="" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
      <label class="screen-reader-text" for="mce-EMAIL">Email Address</label>
      <div class="newsletter-box" id="mc_embed_signup_scroll">
        <input type="email" name="EMAIL" placeholder="Email address" class="email-input" id="mce-EMAIL" required>
        <input type="submit" value="Subscribe" name="subscribe" class="subscribe-btn" id="mc-embedded-subscribe">
      </div>
    </form>
  </div>
</div> <!-- End Newsletter -->

        <section class="comment-area">
    <div class="comment-wrapper">
        

        
    </div>
</section> <!-- End Comment Area -->
      </div>
    </div> <!-- End Wrapper -->
  </article>
  <div class="search-box">
  <div class="wrapper">
    <div class="search-grid">
      <form class="search-form">
        <div id="search-container">
          <input type="text" id="search-input" class="search" placeholder="Search">
        </div>
      </form>
      <ul id="results-container" class="results-search"></ul>
      <div class="icon-close-container">
        <span class="search-icon-close"><i class="fa fa-times" aria-hidden="true"></i></span>
      </div>
    </div>
  </div>
</div>

  




<footer class="main-footer">
    <div class="footer-wrapper">
        <div class="logo-symbol">
            <a class="logo-link" title="Tropical Insights" href="../../">
<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
     width="45px" height="45px" viewBox="0 0 283.46 283.46" xml:space="preserve">
    <g id="Circle">
        <circle fill="none" stroke="#000000" stroke-width="7" stroke-miterlimit="10" cx="141.73" cy="141.73" r="137.501"/>
    </g>
    <g id="Palm_tree">
        <g id="Stem">
            <path fill="#CA9E67" d="M123.059,103.333c24.271,71.429-13.726,156.866-13.726,156.866l47.714,6.396
                c0,0,30.719-110.32,5.229-159.34C156.072,95.324,147.568,95.199,123.059,103.333z"/>
            <path fill="#B17F4A" d="M131.128,124.546c19.709-11.265,21.713,4.12,35.372-0.341l4.861,26.84c0,0-31.309-16.781-39.826,0.34
                l1.655,23.008c12.88-12.255,25.818,10.134,37.38,2.568c0.52,7.122,2.523,22.543-2.908,26.335
                c-8.436,5.891-23.561-14.524-40.673-4.367c-1.837,9.003-6.754,21.405-3.068,18.507c10.894-8.565,30.175,10.716,41.324,1.871
                c5.391-4.278,0.207,22.312-4.713,27.123c-8.715,8.519-27.341-14.03-43.691-5.534C137.429,199.719,136.357,157.553,131.128,124.546
                z"/>
        </g>
        <g id="leaves">
            <path fill="#3AAA35" d="M133.19,64.449c10.912-8.17,25.576-1.329,43.464,6.535c27.123,5.882,56.535,8.169,62.092,90.522
                c-25.92-30.282-52.082-50.452-79.469-57.239c-13.67,5.275-22.167-5.183-33.001,4.306c-35.294,11.438-52.237,30.711-65.636,79.077
                c-14.38-24.739-21.896-74.184,22.222-101.634C95.751,72.912,117.784,61.522,133.19,64.449z"/>
            <path fill="#006633" d="M27.635,92.23c0,0,43.79-76.475,102.613-28.436c40.85-74.023,100.328-9.146,100.328-9.146
                s-39.545-9.484-55.883,18.62c-13.072-7.193-33.742-10.458-42.811-3.922c-15.36-3.595-34.968,7.513-47.059,18.627
                C65.869,71.96,27.635,92.23,27.635,92.23z"/>
        </g>
        <g id="Contour">
            <path fill="none" stroke="#000000" stroke-width="7" stroke-miterlimit="10" d="M27.635,92.23c0,0,43.79-76.475,102.613-28.436
                c40.85-74.023,100.328-9.146,100.328-9.146s-37.584-11.769-53.922,16.336c27.123,5.882,56.535,8.169,62.092,90.522
                c-25.92-30.282-52.082-50.452-79.469-57.239c10.783,23.856,22.279,63.634-2.23,162.328c-14.788-3.618-28.433-5.088-47.714-6.396
                c34.313-71.569,23.284-142.529,16.943-151.626c-35.294,11.438-52.237,30.711-65.636,79.077
                c-14.38-24.739-21.896-74.184,22.222-101.634C63.908,70.003,27.635,92.23,27.635,92.23z"/>
        </g>
    </g>
</svg>

            </a>
        </div>
        <div class="copyright">
          <p>2024 &copy; Hernan Iriarte</p>
        </div>
        <div class="footer-nav">
            <div>
                <a href="../../archive.html">
                    Posts
                </a>
            </div>
            <div>
                <a href="../../tags.html">
                    Tags
                </a>
            </div>
            <div>
                <a href="../../about.html">
                    About me
                </a>
            </div>
        </div>
    </div>
</footer> <!-- End Footer -->

</div>

    <div class="top" title="Top">
      <svg aria-hidden="true" focusable="false" data-prefix="fal" data-icon="angle-up" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="svg-inline--fa fa-angle-up fa-w-8 fa-2x"><path fill="currentColor" d="M136.5 185.1l116 117.8c4.7 4.7 4.7 12.3 0 17l-7.1 7.1c-4.7 4.7-12.3 4.7-17 0L128 224.7 27.6 326.9c-4.7 4.7-12.3 4.7-17 0l-7.1-7.1c-4.7-4.7-4.7-12.3 0-17l116-117.8c4.7-4.6 12.3-4.6 17 .1z" class=""></path></svg>
    </div>
    




<!-- JS -->








<script>
(function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var logo = document.getElementById('logo');
    var nightModeOption = ('manual' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
    storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
    var data = storage.getItem('theme');
    try {
        data = JSON.parse(data ? data : '');
    } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
    }
    return data;
    }

    function handleThemeToggle(nightShift) {
    themeData.nightShift = nightShift;
    saveThemeData(themeData);
    html.dataset.theme = nightShift ? 'dark' : 'light';
    if (nightShift) {
        logo.setAttribute("src", "../../assets/img/branding/logo-full-dark.svg");
    } else {
        logo.setAttribute("src", "../../assets/img/branding/logo-full.svg");
    }
    setTimeout(function() {
        sw.checked = nightShift ? true : false;
    }, 50);
    }

    function autoThemeToggle() {
    // Next time point of theme toggle
    var now = new Date();
    var toggleAt = new Date();
    var hours = now.getHours();
    var nightShift = hours >= 19 || hours <=7;

    if (nightShift) {
        if (hours > 7) {
        toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
    } else {
        toggleAt.setHours(19);
    }

    toggleAt.setMinutes(0);
    toggleAt.setSeconds(0);
    toggleAt.setMilliseconds(0)

    var delay = toggleAt.getTime() - now.getTime();

    // auto toggle theme mode
    setTimeout(function() {
        handleThemeToggle(!nightShift);
    }, delay);

    return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
    };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
    handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
    var data = autoThemeToggle();

    // Toggle theme by local setting
    if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
    } else {
        handleThemeToggle(themeData.nightShift);
    }
    } else if (nightModeOption == 'manual') {
    handleThemeToggle(themeData.nightShift);
    } else {
    var nightShift = themeData.nightShift;
    if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
    }
    handleThemeToggle(nightShift);
    }
})();
</script>

<script src="../../assets/js/jekyll-search.js"></script>
<script src="../../assets/js/jquery-3.6.0.min.js"></script>


  <script>
    function toggle_comments(){
      var commentCurtain = document.getElementById('comment-curtain')
      if (commentCurtain) {
        commentCurtain.classList.toggle('hide')
      }
      var disqusThread = document.getElementById('comment-layout')
      if (disqusThread) {
        disqusThread.classList.toggle('show')
      }
    }

    function copyToClipboard() {
      navigator.clipboard.writeText('http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html').then(function() {
      alerts = document.getElementsByClassName('alert')
      for (i=0; i < alerts.length; i++){
        alerts[i].innerHTML='\u00ABlink copied\u00BB';
        setTimeout((function(i){ return function(){alerts[i].innerHTML='';}})(i), 1600 );
      };
      }, function() {
        prompt("Unable to copy, please use this link:", "http://localhost:4000/Legacy/Posts/2021-03-12-neural-network-optimization-methods.html");
      });
    }

    $(function () {
      if (document.getElementById('comment-curtain') == null){
        var disqusThread = document.getElementById('comment-layout')
        if (disqusThread) {
          disqusThread.classList.toggle('show')
        }
      }

      var tweetTags = document.getElementsByTagName("tweet");

      if (tweetTags != null){
        for (i=0; i<tweetTags.length; i++){
          tweetA = document.createElement("a")
          tweetA.href = 'https://twitter.com/share?text='
                       + encodeURIComponent(tweetTags[i].textContent)
                       + '&via=&url='
                       + window.location.href;
          tweetA.target = "_blank";
          tweetA.className = 'twitter';
          tweetSpanText = document.createElement('span');
          tweetSpanText.className = 'tweetText';
          tweetSpanText.appendChild(document.createTextNode(tweetTags[i].textContent));
          tweetSpanIcon = document.createElement('span');
          tweetSpanIcon.className = 'tweetIcon';
          tweetSpanIcon.appendChild(document.createTextNode("click to tweet"));
          tweetI = document.createElement("i");
          tweetI.className = 'fa fa-twitter';
          tweetSpanIcon.appendChild(tweetI);
          tweetA.appendChild(tweetSpanText);
          tweetA.appendChild(tweetSpanIcon);
          tweetTags[i].textContent = "";
          tweetTags[i].appendChild(tweetA);
        }
      }

    });

  </script>
  <!-- Mailchimp linking -->
  <script id="mcjs">!function(c,h,i,m,p){m=c.createElement(h),p=c.getElementsByTagName(h)[0],m.async=1,m.src=i,p.parentNode.insertBefore(m,p)}(document,"script","https://chimpstatic.com/mcjs-connected/js/users/8ece198b3eb260e6838461a60/d20d9fb9aad962399025da52e.js");</script>



  <script src="https://cdn.jsdelivr.net/gh/cferdinandi/gumshoe@5.1.1/dist/gumshoe.polyfills.min.js"></script>
  <script>
    var spy = new Gumshoe("#toc-content a", {
      navClass:"active",
      contentClass:"underline",
      nested:0,
      nestedClass:"active",
      offset:20,
      reflow:1,
      events:1
    });

    var coll = document.getElementsByClassName("toc-item-1");
    var i;
    var chevron_up = "<svg aria-hidden=\"true\" focusable=\"false\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><path fill=\"currentColor\" d=\"M136.5 185.1l116 117.8c4.7 4.7 4.7 12.3 0 17l-7.1 7.1c-4.7 4.7-12.3 4.7-17 0L128 224.7 27.6 326.9c-4.7 4.7-12.3 4.7-17 0l-7.1-7.1c-4.7-4.7-4.7-12.3 0-17l116-117.8c4.7-4.6 12.3-4.6 17 .1z\"></path></svg>"
    var chevron_down = "<svg aria-hidden=\"true\" focusable=\"false\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\"><path fill=\"currentColor\" d=\"M119.5 326.9L3.5 209.1c-4.7-4.7-4.7-12.3 0-17l7.1-7.1c4.7-4.7 12.3-4.7 17 0L128 287.3l100.4-102.2c4.7-4.7 12.3-4.7 17 0l7.1 7.1c4.7 4.7 4.7 12.3 0 17L136.5 327c-4.7 4.6-12.3 4.6-17-.1z\"></path></svg>"
    for (i = 0; i < coll.length; i++) {
      if (coll[i].childElementCount > 1) {
        sign = document.createElement('div');
        sign.className = "toc-sign";
        sign.innerHTML = chevron_down;
        coll[i].insertBefore(sign, coll[i].childNodes[0].nextSibling);
        coll[i].addEventListener("click", function() {
          var content = this.lastElementChild;
          if (content.style.maxHeight){
            content.style.maxHeight = null;
            this.firstElementChild.nextSibling.innerHTML = chevron_down;
          } else {
            content.style.maxHeight = content.scrollHeight + "px";
            this.firstElementChild.nextSibling.innerHTML = chevron_up;
          }
        });
      }
    }
  </script>



  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "CommonHTML": { linebreaks: { automatic: true } }
    });
  </script>
  <script src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<script src="../../assets/js/main.js"></script>
<script>
  SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('results-container'),
      json: '../../search.json',
      searchResultTemplate: '<li><a href="{url}" title="{description}">{title}</a><p>{description}</p></li>',
      noResultsText: 'No results found',
      fuzzy: false,
      exclude: ['Welcome']
    });
</script>




    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GTM-KJZ983L4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'GTM-KJZ983L4');
</script>
  </body>
</html>
